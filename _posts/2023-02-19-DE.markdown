---
layout: post
title:  "Differential Evolution"
date:   2023-02-19 10:59:22 +0800
categories: algorithm
---
{% include math.html %}
Differential Evolution (DE) [ref.] is a global optimization algorithm over continuous space which can be used for quantum control [ref.]. It consists of three steps in each iteration, mutation, crossover and selection.

First, we create a population for the parameters we want to optimize. An individual in the population is a $$D$$-dimensional vector $$X_{i}$$, $$i=1,2,3,…,N_\text{P}$$, where $$D$$ is the number of parameters and $$N_\text{P}$$ is the population size. For each iteration, four different individuals $$X_{i},X_{s1},X_{s2},X_{s3}$$ will be sampled randomly from the population.

{% highlight python %}
def createPopulation(param_min, param_max, D, Np):
    # param_min and param_max are the lower and upper limit of your parameters
    population = np.reshape( np.random.uniform(param_min, param_max, D*Np), (Np, D) )
    return population
{% endhighlight %}

# Mutation
The mutant vector $$V_{i}$$ is obtained by

$$\begin{equation}
    V_{i} = X_{s1} + \mu (X_{s2} - X_{s3} )
\end{equation}$$

with $$\mu \in [0,2]$$ the mutation factor which controls the differential variation $$X_{s2} - X_{s3}$$.

{% highlight python %}
def mutation(mu=0.5):
    # Sample four different individuals
    sampled = np.array(random.sample(range(0, Np), 4))
    Xi = population[sampled[0]]
    Xs1 = population[sampled[1]]
    Xs2 = population[sampled[2]]
    Xs3 = population[sampled[3]]

    # Generate mutant vector
    Vi = Xs1 + mu * (Xs2 - Xs3)
    return Vi
{% endhighlight %}

# Crossover
To increase the diversity of the perturbed parameter vectors, the trail vector $$U_{i}$$ is obtained by

$$\begin{equation}
    U_{i} = 
    \begin{cases}
        V_{i} & \text{if}\ c(0,1) < \xi,\\
        X_{i} & \text{otherwise},
    \end{cases}
\end{equation}$$

with $$c(0,1)$$ the uniform random number between 0 and 1 which is sampled in every iteration, and $$\xi \in (0,1)$$ the crossover rate.

{% highlight python %}
def crossover(xi=0.9):
    c = np.random.uniform(0,1)
    # Generate trail vector
    if c < xi:
        Ui = Vi
    else:
        Ui = Xi
        # Start new iteration
{% endhighlight %}

# Selection
The member of the next generation $$X'_{i}$$ is chosen by

$$\begin{equation}
    X'_{i} = 
    \begin{cases}
        U_{i} & \text{if}\ f(U_{i}) < f(X_{i}),\\
        X_{i} & \text{otherwise},
    \end{cases}
\end{equation}$$

where $$f$$ is the cost function of the optimization problem. For example, if we are trying to optimize a trading strategy, f could be the risk-reward ratio, win rate, etc.

{% highlight python %}
def selection(f):
    # f is the cost function
    fu = f(Ui)
    fx = f(Xi)
    if fu < fx:
        # Replace Xi with Ui
        population[sampled[0]] = Ui
    else:
        # Start new iteration
{% endhighlight %}




Check out the [Jekyll docs][jekyll-docs] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll’s GitHub repo][jekyll-gh]. If you have questions, you can ask them on [Jekyll Talk][jekyll-talk].

[jekyll-docs]: https://jekyllrb.com/docs/home
[jekyll-gh]:   https://github.com/jekyll/jekyll
[jekyll-talk]: https://talk.jekyllrb.com/
